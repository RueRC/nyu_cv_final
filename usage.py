import os
from glob import glob
import numpy as np
import torch
from scipy.spatial.transform import Rotation as R
from dust3r.inference import inference
from dust3r.model import AsymmetricCroCo3DStereo
from dust3r.utils.image import load_images
from dust3r.image_pairs import make_pairs
from dust3r.cloud_opt import global_aligner, GlobalAlignerMode

# === ä½ çš„ä¿å­˜å‡½æ•°ç›´æ¥å¤ç”¨ ===
from usage import save_colmap_model_with_points  # å¦‚æœå®šä¹‰åœ¨åŒæ–‡ä»¶é‡Œå°±ä¸ç”¨å¯¼å…¥

# === ä¸»è¦å‚æ•° ===
ROOT_DIR = "/local_data/xl3136/DATA/wanderland_eval"
OUTPUT_ROOT = "/local_data/yz10442/dust3r/output"
os.makedirs(OUTPUT_ROOT, exist_ok=True)

device = torch.device("cuda")
batch_size = 1
schedule = "cosine"
lr = 0.01
niter = 300
model_name = "naver/DUSt3R_ViTLarge_BaseDecoder_224_dpt"
model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)

# === éå†æ¯ä¸ªå­æ–‡ä»¶å¤¹ ===
all_folders = sorted(os.listdir(ROOT_DIR))
print(f"å‘ç° {len(all_folders)} ä¸ªæ–‡ä»¶å¤¹ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")

start_idx = 177  # ä»ç¬¬ä¸‰ä¸ªæ–‡ä»¶å¤¹å¼€å§‹ï¼ˆPython ä» 0 å¼€å§‹è®¡æ•°ï¼‰

for idx, folder in enumerate(all_folders[start_idx:], start=start_idx):
    folder_path = os.path.join(ROOT_DIR, folder)
    if not os.path.isdir(folder_path):
        continue

    print(f"\nğŸš€ [{idx+1}/{len(all_folders)}] å¤„ç†: {folder}")
    image_dir = os.path.join(folder_path, "images")  # å‡è®¾å›¾ç‰‡ç›´æ¥åœ¨å­æ–‡ä»¶å¤¹é‡Œ
    all_images = sorted(glob(os.path.join(image_dir, "*.png")) + glob(os.path.join(image_dir, "*.jpg")))
    image_paths = all_images[:43]
    print(f"Loading {len(image_paths)} images (first 50 of total {len(all_images)})")
    if len(all_images) < 2:
        print(f"âš ï¸ æ–‡ä»¶å¤¹ {folder} å›¾ç‰‡æ•°ä¸è¶³ 2ï¼Œè·³è¿‡ã€‚")
        continue

    # === è½½å…¥å›¾ç‰‡ ===
    images = load_images(image_paths, size=512)
    for im_dict in images:
        im_dict["img"] = im_dict["img"].to(device)
    pairs = make_pairs(images, scene_graph='swin-30', prefilter=None, symmetrize=False)
    output = inference(pairs, model, device, batch_size=batch_size)

    # === å…¨å±€é…å‡† ===
    scene = global_aligner(output, device=device, mode=GlobalAlignerMode.ModularPointCloudOptimizer)
    _ = scene.compute_global_alignment(init="mst", niter=niter, schedule=schedule, lr=lr)

    # === å¯¼å‡ºç»“æœ ===
    out_dir = os.path.join(OUTPUT_ROOT, folder)
    os.makedirs(out_dir, exist_ok=True)
    poses = scene.get_im_poses()
    focals = scene.get_focals()
    imgs = scene.imgs
    pts3d = scene.get_pts3d()

    np.save(os.path.join(out_dir, "poses2.npy"), poses.detach().cpu().numpy())
    save_colmap_model_with_points(
        out_dir=out_dir,
        poses_npy_path=os.path.join(out_dir, "poses2.npy"),
        image_paths=image_paths,
        pts3d=pts3d,
        focals=focals.detach().cpu().numpy(),
        wh=(512, 384),
        camera_model="PINHOLE",
        fix_axes=False,
        color_from_imgs=imgs
    )

    print(f"âœ… å®Œæˆ {folder}ï¼Œç»“æœä¿å­˜è‡³ {out_dir}")

    # === æ¸…ç†æ˜¾å­˜ ===
    del images, pairs, output, scene, poses, focals, imgs, pts3d
    torch.cuda.empty_cache()
    torch.cuda.ipc_collect()

print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼")
